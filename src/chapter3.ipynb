{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 CF 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def get_dataset_1() -> \"pd.DataFrame\":\n",
    "  \"\"\"users, movies, ratings dataframe을 반환하는 함수\n",
    "\n",
    "  Returns:\n",
    "      pd.DataFrame: users, movies, ratings dataframe\n",
    "  \"\"\"\n",
    "  u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "  i_cols = ['movie_id', 'title', 'release_date', 'video release date', 'IMDB URL', 'unknown',\n",
    "            'Action', 'Adventure', 'Animation', 'children\\s', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
    "            'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War',\n",
    "            'Western']\n",
    "  r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "\n",
    "  users = pd.read_csv('../data2/u.user', sep='|', names=u_cols, encoding='latin-1')\n",
    "    \n",
    "  movies = pd.read_csv('../data2/u.item', sep='|', names=i_cols, encoding='latin-1')\n",
    "  movies = movies[['movie_id', 'title']]\n",
    "  \n",
    "  ratings = pd.read_csv('../data2/u.data', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "  ratings.drop('timestamp', axis=1, inplace=True)\n",
    "  \n",
    "  return users, movies, ratings\n",
    "\n",
    "users, movies, ratings = get_dataset_1()\n",
    "\n",
    "X = ratings.copy()\n",
    "y = ratings['user_id']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=25)\n",
    "\n",
    "rating_matrix = X_train.pivot(index=\"user_id\", columns='movie_id', values='rating')\n",
    "\n",
    "def RMSE(y_true:\"pd.Series\"or \"np.array\", y_pred:\"pd.Series\") -> float:\n",
    "  \"\"\"_summary_\n",
    "\n",
    "  Args:\n",
    "      y_true (pd.Series&quot;or&quot;np.array): y의 정답\n",
    "      y_pred (pd.Series&quot;or&quot;np.array): y의 예측치\n",
    "\n",
    "  Returns:\n",
    "      float: RMSE\n",
    "  \"\"\"\n",
    "  return np.sqrt(np.mean((np.array(y_true)-np.array(y_pred))**2))\n",
    "\n",
    "# 모델별 RMSE를 계산하는 함수\n",
    "def score(model) -> float:\n",
    "  \"\"\"모델별 RMSE를 계산하는 함수\n",
    "\n",
    "  Args:\n",
    "      model (_type_): rating을 예측하는 모델\n",
    "\n",
    "  Returns:\n",
    "      float: RMSE\n",
    "  \"\"\"\n",
    "  id_pairs = zip(X_test['user_id'], X_test['movie_id'])\n",
    "  \n",
    "  y_pred = np.array([model(user_id, movie_id) for (user_id, movie_id) in id_pairs])\n",
    "  y_true = np.array(X_test['rating'])\n",
    "\n",
    "  return RMSE(y_true, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이웃을 전체 사용자로 설정\n",
    "def CF_simple(user_id:str, movie_id:str) -> float:\n",
    "  \"\"\"이웃을 전체 사용자로 설정하고, \n",
    "  주어진 영화에 대해서 평가한 각 사용자에 대해서, 평점을 유사도로 가중평균한 예측치를 구함.\n",
    "  즉, 해당 user id가 movie id를 어떻게 평가할 것인지를 유사도로 평점을 가중평균해 예측하는 함수 \n",
    "\n",
    "  Args:\n",
    "      user_id (str): 사용자 id\n",
    "      movie_id (str): movie id\n",
    "\n",
    "  Returns:\n",
    "      float: user id와 movie id를 평가한 사용자에 대한, 유사도로 평점을 가중평균한 예측치\n",
    "  \"\"\"\n",
    "  # 해당 movie id에 대해서 평가한 값이 있는지 확인\n",
    "  if movie_id in rating_matrix.columns:\n",
    "    movie_ratings = rating_matrix[movie_id].copy()\n",
    "    # movie_id에 대해서 평가하지 않은 user \n",
    "    none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
    "    movie_ratings = movie_ratings.dropna()\n",
    "    \n",
    "    sim_scores = user_similarity[user_id].copy()\n",
    "    sim_scores = sim_scores.dropna()\n",
    "    # 평가하지 않은 유저는 뺴준다.\n",
    "    sim_scores = sim_scores.drop(none_rating_idx, axis=0)\n",
    "    \n",
    "    # 주어진 영화에 대해서 평가한 각 사용자에 대해서 평점을 유사도로 가중평균한 예측치를 구함\n",
    "    mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "  # 없으면 3.0으로 예측\n",
    "  else:\n",
    "    mean_rating = 3.0\n",
    "    \n",
    "  return mean_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0196376882827216"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(CF_simple)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연습문제   \n",
    "위의 코드를 수정해서 코사인 유사도 대신에 피어슨 상관계수를 사용하는 코드를 작성하고 RMSE를 계산하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "user_corr = matrix_dummy.T.corr()\n",
    "user_corr = pd.DataFrame(user_corr, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "def CF_simple_using(simil:str):\n",
    "  \"\"\"similarity를 어떻게 계산할지 여부에 따라 해당 model을 return하는 함수\n",
    "\n",
    "  Args:\n",
    "      simil (str): similarity계산 방식 ( cosine or corr )\n",
    "\n",
    "  Raises:\n",
    "      Exception: simil값이 정확하지 않을 때\n",
    "\n",
    "  Returns:\n",
    "      _type_: CF_simple model\n",
    "  \"\"\"\n",
    "  if simil == 'cosine':\n",
    "    return CF_simple_cosine\n",
    "  elif simil == 'corr':\n",
    "    return CF_simple_corr\n",
    "  else:\n",
    "    raise Exception('simil값을 확인해주세요 (cosine or corr)')    \n",
    "\n",
    "# 이웃을 전체 사용자로 설정\n",
    "def CF_simple_cosine(user_id:str, movie_id:str) -> float:\n",
    "  \"\"\"이웃을 전체 사용자로 설정하고, \n",
    "  주어진 영화에 대해서 평가한 각 사용자에 대해서, 평점을 유사도로 가중평균한 예측치를 구함.\n",
    "  즉, 해당 user id가 movie id를 어떻게 평가할 것인지를 유사도로 평점을 가중평균해 예측하는 함수 \n",
    "  유사도 : cosine similarity\n",
    "  Args:\n",
    "      user_id (str): 사용자 id\n",
    "      movie_id (str): 영화 id\n",
    "  Returns:\n",
    "      float: user id와 movie id를 평가한 사용자에 대한, 유사도로 평점을 가중평균한 예측치\n",
    "  \"\"\"\n",
    "  # 해당 movie id에 대해서 평가한 값이 있는지 확인\n",
    "  if movie_id in rating_matrix.columns:\n",
    "    movie_ratings = rating_matrix[movie_id].copy()\n",
    "    # movie_id에 대해서 평가하지 않은 user \n",
    "    none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
    "    movie_ratings = movie_ratings.dropna()\n",
    "    \n",
    "    sim_scores = user_similarity[user_id].copy()\n",
    "    sim_scores = sim_scores.dropna()\n",
    "    # 평가하지 않은 유저는 뺴준다.\n",
    "    sim_scores = sim_scores.drop(none_rating_idx, axis=0)\n",
    "    \n",
    "    # 주어진 영화에 대해서 평가한 각 사용자에 대해서 평점을 유사도로 가중평균한 예측치를 구함\n",
    "    mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "  # 없으면 3.0으로 예측\n",
    "  else:\n",
    "    mean_rating = 3.0\n",
    "    \n",
    "  return mean_rating\n",
    "\n",
    "# 이웃을 전체 사용자로 설정\n",
    "def CF_simple_corr(user_id:str, movie_id:str) -> float:\n",
    "  \"\"\"이웃을 전체 사용자로 설정하고, \n",
    "  주어진 영화에 대해서 평가한 각 사용자에 대해서, 평점을 유사도로 가중평균한 예측치를 구함.  \n",
    "  즉, 해당 user id가 movie id를 어떻게 평가할 것인지를 유사도로 평점을 가중평균해 예측하는 함수.\n",
    "  유사도: correlation\n",
    "  \n",
    "  Args:\n",
    "      user_id (str): 사용자 id\n",
    "      movie_id (str): 영화 id\n",
    "  Returns:\n",
    "      float: user id와 movie id를 평가한 사용자에 대한, 유사도로 평점을 가중평균한 예측치\n",
    "  \"\"\"\n",
    "  # 해당 movie id에 대해서 평가한 값이 있는지 확인\n",
    "  if movie_id in rating_matrix.columns:\n",
    "    movie_ratings = rating_matrix[movie_id].copy()\n",
    "    # movie_id에 대해서 평가하지 않은 user \n",
    "    none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
    "    movie_ratings = movie_ratings.dropna()\n",
    "    \n",
    "    sim_scores = user_corr[user_id].copy()\n",
    "    sim_scores = sim_scores.dropna()\n",
    "    # 평가하지 않은 유저는 뺴준다.\n",
    "    sim_scores = sim_scores.drop(none_rating_idx, axis=0)\n",
    "    \n",
    "    # 주어진 영화에 대해서 평가한 각 사용자에 대해서 평점을 유사도로 가중평균한 예측치를 구함\n",
    "    mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "  # 없으면 3.0으로 예측\n",
    "  else:\n",
    "    mean_rating = 3.0\n",
    "    \n",
    "  return mean_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smilarity: cosine , 1.0196\n",
      "smilarity: corr , 1.1566\n"
     ]
    }
   ],
   "source": [
    "print(f\"smilarity: cosine , {score(CF_simple_using(simil='cosine')):.4f}\")\n",
    "print(f\"smilarity: corr , {score(CF_simple_using(simil='corr')):.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이웃을 고려한 CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델별 RMSE를 계산하는 함수\n",
    "def score_CF(model, simil:str='cosine', neighbor_size:int=0) -> float:\n",
    "  \"\"\"CF 모델별 RMSE를 계산하는 함수\n",
    "\n",
    "  Args:\n",
    "      model (_type_): rating을 예측하는 CF 모델 \\n\n",
    "      simil (str): similarity계산 방식 ( cosine or corr )\\n\n",
    "      neighbor_size (int): 이웃의 수 \\n\n",
    "  Raises:\n",
    "      Exception: simil값이 정확하지 않을 때\n",
    "  Returns:\n",
    "      float: RMSE\n",
    "  \"\"\"\n",
    "  if not(simil == 'cosine' or simil == 'corr'):\n",
    "    raise Exception('simil값을 확인해주세요 (cosine or corr)')   \n",
    "  \n",
    "  id_pairs = zip(X_test['user_id'], X_test['movie_id'])\n",
    "  \n",
    "  y_pred = np.array([model(user_id, movie_id, simil, neighbor_size) for (user_id, movie_id) in id_pairs])\n",
    "  y_true = np.array(X_test['rating'])\n",
    "\n",
    "  return RMSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이웃을 전체 사용자로 설정\n",
    "def CF_knn(user_id:str, movie_id:str, simil: str, neighbor_size: int) -> float:\n",
    "  \"\"\"이웃을 전체 사용자로 설정하고, \n",
    "  주어진 영화에 대해서 평가한 각 사용자에 대해서, 평점을 유사도로 가중평균한 예측치를 구함.\\n\n",
    "  즉, 해당 user id가 movie id를 어떻게 평가할 것인지를 유사도로 평점을 가중평균해 예측하는 함수. \\n\n",
    "  유사도: correlation or cosine \\n\n",
    "  유사도 기준 상위 neighbor_size(k)만큼을 이웃으로 정의. 이웃에 대해서만 가중평균을 진행.\\n\n",
    "  \n",
    "  Args:\n",
    "      user_id (str): 사용자 id \\n\n",
    "      movie_id (str): 영화 id \\n\n",
    "      simil (str): similarity계산 방식 ( cosine or corr ) \\n\n",
    "      neighbor_size (int): 이웃의 수 \\n\n",
    "  Returns:\n",
    "      float: user id와 movie id를 평가한 사용자에 대한, 유사도로 평점을 가중평균한 예측치\n",
    "  \"\"\"\n",
    "  if simil == 'cosine':\n",
    "    similarity = user_similarity\n",
    "  else:\n",
    "    similarity = user_corr\n",
    "  \n",
    "  # 해당 movie id에 대해서 평가한 값이 있는지 확인 ( train set에 movie id가 있는지 확인 )\n",
    "  if movie_id in rating_matrix.columns:\n",
    "    movie_ratings = rating_matrix[movie_id].copy()\n",
    "    # movie_id에 대해서 평가하지 않은 user \n",
    "    none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
    "    movie_ratings = movie_ratings.dropna()\n",
    "    \n",
    "    sim_scores = similarity[user_id].copy()\n",
    "    sim_scores = sim_scores.dropna()\n",
    "    # 평가하지 않은 유저는 뺴준다.\n",
    "    sim_scores = sim_scores.drop(none_rating_idx, axis=0)\n",
    "    sim_scores.sort_values(ascending=False, inplace=True)\n",
    "    # 유사도 개수가 0일 때 \n",
    "    if len(sim_scores) == 0:\n",
    "      mean_rating = 3.0\n",
    "      return mean_rating\n",
    "    \n",
    "    # 주어진 영화에 대해서 평가한 각 사용자에 대해서 평점을 유사도로 가중평균한 예측치를 구함\n",
    "    # k가 0인경우 ( 안주어진 경우 )\n",
    "    if neighbor_size == 0:\n",
    "      mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "    # K가 주어진 경우\n",
    "    else: \n",
    "      neighbor_size = min(neighbor_size, len(sim_scores))\n",
    "      \n",
    "      sim_scores = sim_scores[:neighbor_size]      \n",
    "      movie_ratings = movie_ratings[sim_scores.index][:neighbor_size]\n",
    "        \n",
    "      mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "  # 없으면 3.0으로 예측\n",
    "  else:\n",
    "    mean_rating = 3.0\n",
    "    \n",
    "  return mean_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9022245790355954"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_CF(CF_knn, simil='cosine', neighbor_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터셋에 대해서 추천\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "rating_matrix = ratings.pivot_table(values='rating', index='user_id', columns='movie_id')\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "def recommender_CF(user_id:str, n_items:int=10, neighbor_size:int=20) -> \"pd.DataFrame\":\n",
    "  \"\"\"user id에 대해서 비슷한 이웃 (cosine 유사도 기반 상위 neighbor_size만큼) 과의 유사도와 \\n\n",
    "  평점을 가중평균한 가중평균을 기반으로 , 상위 n_items 개수만큼 추출하여 추천해주는 함수.\n",
    "\n",
    "  Args:\n",
    "      user_id (str): 추천받고자 하는 사용자 id \\n\n",
    "      n_items (int, optional): 추천받고 싶은 movie의 개수. Defaults to 10. \\n\n",
    "      neighbor_size (int, optional): 가중평균 구할 때 사용할 이웃의 숫자. Defaults to 20. \\n\n",
    "\n",
    "  Returns:\n",
    "      pd.Series: 추천하는 영화 dataframe\n",
    "  \"\"\"\n",
    "  predictions = []\n",
    "\n",
    "  user_rating = matrix_dummy.loc[user_id]\n",
    "  # 평가하지 않은 영화에 대해서 추리기\n",
    "  items = user_rating[user_rating == 0]\n",
    "  # 앞서 구현한 CF_knn을 이용해 유사도 기반 가중평균값 구하기\n",
    "  for item in items.index:\n",
    "    predictions.append(CF_knn(user_id, item, simil='cosine', neighbor_size=neighbor_size))\n",
    "  # 가중평균을 기준으로 정렬. 상위 n_items개수만큼 추출.\n",
    "  recommendations = pd.Series(data=predictions, index=items.index, dtype=float)\n",
    "  recommendations = recommendations.sort_values(ascending=False)[:n_items]\n",
    "  # 상위 movies들에 대해 제목과 예측점수 return.\n",
    "  recommended_items = pd.DataFrame()\n",
    "  recommended_items['title'] = movies.loc[recommendations.index]['title']\n",
    "  recommended_items['predicted rating'] =  recommendations.values\n",
    "  \n",
    "  return recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>predicted rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>Chairman of the Board (1998)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>Cosi (1996)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>Last Time I Saw Paris, The (1954)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>That Old Feeling (1997)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>One Fine Day (1996)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  predicted rating\n",
       "movie_id                                                     \n",
       "1653           Chairman of the Board (1998)               5.0\n",
       "1536                            Cosi (1996)               5.0\n",
       "1122      Last Time I Saw Paris, The (1954)               5.0\n",
       "1189                That Old Feeling (1997)               5.0\n",
       "814                     One Fine Day (1996)               5.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender_CF(user_id=2, n_items=5, neighbor_size=30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최적의 이웃 크기 결정   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set에 대해서 측정\n",
    "# CF_knn 보완해야되는 부분. 따로 user_similarity, user_corr 할당해주고 써야되는 문제.\n",
    "X = ratings.copy();y = ratings['user_id']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=25)\n",
    "rating_matrix = X_train.pivot(index=\"user_id\", columns='movie_id', values='rating')\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "user_corr = matrix_dummy.T.corr()\n",
    "user_corr = pd.DataFrame(user_corr, index=rating_matrix.index, columns=rating_matrix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbor_size : 10 / RMSE : 1.0332\n",
      "neighbor_size : 20 / RMSE : 1.0164\n",
      "neighbor_size : 30 / RMSE : 1.0142\n",
      "neighbor_size : 40 / RMSE : 1.0141\n",
      "neighbor_size : 50 / RMSE : 1.0140\n",
      "neighbor_size : 60 / RMSE : 1.0144\n"
     ]
    }
   ],
   "source": [
    "neighbor_sizes = [i for i in range(10, 61)]\n",
    "results = []\n",
    "\n",
    "for k in neighbor_sizes:\n",
    "  result = score_CF(CF_knn, simil='cosine', neighbor_size=k)\n",
    "  results.append(result)\n",
    "  if (k % 10 == 0):\n",
    "    print(f\"neighbor_size : {k} / RMSE : {result:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RMSE')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "result_df = pd.DataFrame(index=neighbor_sizes, data=results, columns=['results'])\n",
    "result_df.plot()\n",
    "\n",
    "min_k =result_df.index[np.argmin(result_df['results'])]\n",
    "min_rmse = result_df.loc[min_k]['results']\n",
    "\n",
    "plt.text(min_k-5, min_rmse+0.001, f'min point ({min_k}, {min_rmse:.4f})', color='orange')\n",
    "plt.plot(min_k, min_rmse, marker='X', color='orange')\n",
    "\n",
    "plt.title('K - RMSE plot')\n",
    "plt.xlabel('# of neighbors')\n",
    "plt.ylabel('RMSE')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40~50 사이에서 최적의 K값을 가질 것이라 판단됨. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>predicted rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>Guantanamera (1994)</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>That Old Feeling (1997)</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>Prisoner of the Mountains (Kavkazsky Plennik) ...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>Pather Panchali (1955)</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>Last Time I Saw Paris, The (1954)</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>Chairman of the Board (1998)</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>Welcome To Sarajevo (1997)</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>Target (1995)</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>Ayn Rand: A Sense of Life (1997)</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>Maybe, Maybe Not (Bewegte Mann, Der) (1994)</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>Little Princess, The (1939)</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>Eye for an Eye (1996)</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>Cure, The (1995)</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Everyone Says I Love You (1996)</td>\n",
       "      <td>4.649704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>Golden Earrings (1947)</td>\n",
       "      <td>4.629313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>Shopping (1994)</td>\n",
       "      <td>4.590544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Snow White and the Seven Dwarfs (1937)</td>\n",
       "      <td>4.572176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Haunted World of Edward D. Wood Jr., The (1995)</td>\n",
       "      <td>4.565335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mighty Aphrodite (1995)</td>\n",
       "      <td>4.525882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Local Hero (1983)</td>\n",
       "      <td>4.521308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Striptease (1996)</td>\n",
       "      <td>4.504050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>Bloody Child, The (1996)</td>\n",
       "      <td>4.494700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>What's Eating Gilbert Grape (1993)</td>\n",
       "      <td>4.481027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>Angel Baby (1995)</td>\n",
       "      <td>4.458634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Cinema Paradiso (1988)</td>\n",
       "      <td>4.433458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Harold and Maude (1971)</td>\n",
       "      <td>4.421708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>It Happened One Night (1934)</td>\n",
       "      <td>4.406271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Full Metal Jacket (1987)</td>\n",
       "      <td>4.398899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>Old Man and the Sea, The (1958)</td>\n",
       "      <td>4.397658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Ridicule (1996)</td>\n",
       "      <td>4.396081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      title  predicted rating\n",
       "movie_id                                                                     \n",
       "1599                                    Guantanamera (1994)          5.000000\n",
       "1189                                That Old Feeling (1997)          5.000000\n",
       "1500      Prisoner of the Mountains (Kavkazsky Plennik) ...          5.000000\n",
       "1448                                 Pather Panchali (1955)          5.000000\n",
       "1122                      Last Time I Saw Paris, The (1954)          5.000000\n",
       "1653                           Chairman of the Board (1998)          5.000000\n",
       "1175                             Welcome To Sarajevo (1997)          5.000000\n",
       "1656                                          Target (1995)          5.000000\n",
       "1293                       Ayn Rand: A Sense of Life (1997)          5.000000\n",
       "1201            Maybe, Maybe Not (Bewegte Mann, Der) (1994)          5.000000\n",
       "1472                            Little Princess, The (1939)          5.000000\n",
       "973                                   Eye for an Eye (1996)          5.000000\n",
       "1467                                       Cure, The (1995)          5.000000\n",
       "318                         Everyone Says I Love You (1996)          4.649704\n",
       "1449                                 Golden Earrings (1947)          4.629313\n",
       "1594                                        Shopping (1994)          4.590544\n",
       "98                   Snow White and the Seven Dwarfs (1937)          4.572176\n",
       "114         Haunted World of Edward D. Wood Jr., The (1995)          4.565335\n",
       "12                                  Mighty Aphrodite (1995)          4.525882\n",
       "515                                       Local Hero (1983)          4.521308\n",
       "119                                       Striptease (1996)          4.504050\n",
       "851                                Bloody Child, The (1996)          4.494700\n",
       "64                       What's Eating Gilbert Grape (1993)          4.481027\n",
       "1642                                      Angel Baby (1995)          4.458634\n",
       "169                                  Cinema Paradiso (1988)          4.433458\n",
       "427                                 Harold and Maude (1971)          4.421708\n",
       "603                            It Happened One Night (1934)          4.406271\n",
       "187                                Full Metal Jacket (1987)          4.398899\n",
       "1125                        Old Man and the Sea, The (1958)          4.397658\n",
       "223                                         Ridicule (1996)          4.396081"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여기서 구한 k값으로 다시 추천 받아보기\n",
    "recommender_CF(user_id=2, n_items=30, neighbor_size=46)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13번째 영화까지는 모두 5.0이므로, 상위 5개만 뽑았다면 나머지 8개는 우연히 추천이 안되는 문제가 발생한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용자의 평가경향을 고려한 CF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{a, i} = \\overline r_a + \\frac\n",
    "{\\sum_{u=1}^nw_{a,u}(r_{u,i} - \\overline r_u)}\n",
    "{\\sum_{u=1}^nw_{a,u}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이웃을 전체 사용자로 설정\n",
    "def CF_knn_bias(user_id:str, movie_id:str, simil: str, neighbor_size: int) -> float:\n",
    "  \"\"\"\n",
    "  주어진 영화에 대해서 평가한 사용자에 대해서, 평점을 기반으로 유사도를 계산하고, 유사도와 평점을 가중평균해 예측치를 구함.\\n\n",
    "  유사도 기준 상위 neighbor_size(=k)만큼을 이웃으로 정의. 이웃에 대해서만 가중평균을 진행.\\n\n",
    "  사용자의 평가경향을 고려 \\n\n",
    "  \n",
    "  Args:\n",
    "      user_id (str): 사용자 id \\n\n",
    "      movie_id (str): 영화 id \\n\n",
    "      simil (str): similarity계산 방식 ( cosine or corr ) \\n\n",
    "      neighbor_size (int): 이웃의 수 \\n\n",
    "  Returns:\n",
    "      float: user id와 movie id를 평가한 사용자에 대한, 유사도로 평점을 가중평균한 예측치\n",
    "  \"\"\"\n",
    "  \n",
    "  # 구할 수 없는 경우에는 평균평점으로 대체한다.\n",
    "  default_rating = rating_mean[user_id]\n",
    "  \n",
    "  # 유사도 기준 설정. \n",
    "  if simil == 'cosine':\n",
    "    similarity = user_similarity\n",
    "  else:\n",
    "    similarity = user_corr\n",
    "  \n",
    "  # 해당 movie id에 대해서 평가한 값이 있는지 확인 ( train set에 movie id가 있는지 확인 )\n",
    "  if movie_id in rating_matrix.columns:\n",
    "    movie_ratings = rating_bias[movie_id].copy() #  rating_bias를 이용해 평가경향 제거해줌.\n",
    "    # movie_id에 대해서 평가하지 않은 user \n",
    "    none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
    "    movie_ratings = movie_ratings.dropna()\n",
    "    \n",
    "    sim_scores = similarity[user_id].copy()\n",
    "    sim_scores = sim_scores.dropna()\n",
    "    # 평가하지 않은 유저는 뺴준다.\n",
    "    sim_scores = sim_scores.drop(none_rating_idx, axis=0)\n",
    "    # 유사도 개수가 0일 때 \n",
    "    if len(sim_scores) == 0:\n",
    "      return default_rating\n",
    "    \n",
    "    # 주어진 영화에 대해서 평가한 각 사용자에 대해서 평점을 유사도로 가중평균한 예측치를 구함\n",
    "    # k가 0인경우 ( 안주어진 경우 )\n",
    "    if neighbor_size == 0:\n",
    "      mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "    # K가 주어진 경우\n",
    "    else:\n",
    "      sim_scores = sim_scores.sort_values(ascending=False)\n",
    " \n",
    "      neighbor_size = min(neighbor_size, len(sim_scores))\n",
    "      \n",
    "      sim_scores = sim_scores[:neighbor_size]      \n",
    "      movie_ratings = movie_ratings[sim_scores.index][:neighbor_size]\n",
    "      \n",
    "      # 사용자의 평가경향 더 해줌\n",
    "      mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum() + default_rating\n",
    "  # 없으면 3.0으로 예측\n",
    "  else:\n",
    "    mean_rating = default_rating\n",
    "    \n",
    "  return mean_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: basic model / rmse: 1.0142086411731543\n",
      "model: bias reducing model / rmse: 0.9441684573734636\n"
     ]
    }
   ],
   "source": [
    "# train set에 대해서 측정\n",
    "# CF_knn 보완해야되는 부분. 따로 user_similarity, user_corr 할당해주고 써야되는 문제.\n",
    "X = ratings.copy();y = ratings['user_id']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=25)\n",
    "rating_matrix = X_train.pivot(index=\"user_id\", columns='movie_id', values='rating')\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "user_corr = matrix_dummy.T.corr()\n",
    "user_corr = pd.DataFrame(user_corr, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "rating_mean = rating_matrix.mean(axis=1)\n",
    "rating_bias = (rating_matrix.T - rating_mean).T # 평가경향 제거\n",
    "\n",
    "print(f\"model: basic model / rmse: {score_CF(CF_knn, simil='cosine', neighbor_size=30)}\")\n",
    "print(f\"model: bias reducing model / rmse: {score_CF(CF_knn_bias, simil='cosine', neighbor_size=30)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연습문제  \n",
    "편향이 제거된 모델을 이용해 사용자 ID를 지정하면 해당 사용자를 위해 5개의 영화를 추천. 위의 결과와 비교.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터셋에 대해서 추천\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "rating_matrix = ratings.pivot_table(values='rating', index='user_id', columns='movie_id')\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "rating_mean = rating_matrix.mean(axis=1)\n",
    "rating_bias = (rating_matrix.T - rating_mean).T # 평가경향 제거\n",
    "\n",
    "def recommender_CF_bias(user_id:str, n_items:int=10, neighbor_size:int=20) -> \"pd.DataFrame\":\n",
    "  \"\"\"user id에 대해서 비슷한 이웃 (cosine 유사도 기반 상위 neighbor_size만큼) 과의 유사도와 \\n\n",
    "  평점을 가중평균한 가중평균을 기반으로 , 상위 n_items 개수만큼 추출하여 추천해주는 함수.\n",
    "\n",
    "  Args:\n",
    "      user_id (str): 추천받고자 하는 사용자 id \\n\n",
    "      n_items (int, optional): 추천받고 싶은 movie의 개수. Defaults to 10. \\n\n",
    "      neighbor_size (int, optional): 가중평균 구할 때 사용할 이웃의 숫자. Defaults to 20. \\n\n",
    "\n",
    "  Returns:\n",
    "      pd.Series: 추천하는 영화 dataframe\n",
    "  \"\"\"\n",
    "  predictions = []\n",
    "\n",
    "  user_rating = matrix_dummy.loc[user_id]\n",
    "  # 평가하지 않은 영화에 대해서 추리기\n",
    "  items = user_rating[user_rating == 0]\n",
    "  # 앞서 구현한 CF_knn을 이용해 유사도 기반 가중평균값 구하기\n",
    "  for item in items.index:\n",
    "    predictions.append(CF_knn_bias(user_id, item, simil='cosine', neighbor_size=neighbor_size))\n",
    "  # 가중평균을 기준으로 정렬. 상위 n_items개수만큼 추출.\n",
    "  recommendations = pd.Series(data=predictions, index=items.index, dtype=float)\n",
    "  recommendations = recommendations.sort_values(ascending=False)[:n_items]\n",
    "  # 상위 movies들에 대해 제목과 예측점수 return.\n",
    "  recommended_items = pd.DataFrame()\n",
    "  recommended_items['title'] = movies.loc[recommendations.index]['title']\n",
    "  recommended_items['predicted rating'] =  recommendations.values\n",
    "  \n",
    "  return recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>predicted rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>One Fine Day (1996)</td>\n",
       "      <td>5.612193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>Cosi (1996)</td>\n",
       "      <td>5.414304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>Cure, The (1995)</td>\n",
       "      <td>5.172151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>Prisoner of the Mountains (Kavkazsky Plennik) ...</td>\n",
       "      <td>5.132155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>Guantanamera (1994)</td>\n",
       "      <td>5.127928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      title  predicted rating\n",
       "movie_id                                                                     \n",
       "814                                     One Fine Day (1996)          5.612193\n",
       "1536                                            Cosi (1996)          5.414304\n",
       "1467                                       Cure, The (1995)          5.172151\n",
       "1500      Prisoner of the Mountains (Kavkazsky Plennik) ...          5.132155\n",
       "1599                                    Guantanamera (1994)          5.127928"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender_CF_bias(2, n_items=5, neighbor_size=46)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 외의 CF 정확도 개선방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>934</th>\n",
       "      <th>935</th>\n",
       "      <th>936</th>\n",
       "      <th>937</th>\n",
       "      <th>938</th>\n",
       "      <th>939</th>\n",
       "      <th>940</th>\n",
       "      <th>941</th>\n",
       "      <th>942</th>\n",
       "      <th>943</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>52.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>27.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>83.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 943 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id    1     2     3     4      5     6      7     8    9     10   ...  \\\n",
       "user_id                                                                ...   \n",
       "1        272.0  18.0   8.0   7.0   80.0  96.0  145.0  34.0  5.0  77.0  ...   \n",
       "2         18.0  62.0   9.0   7.0    5.0  32.0   18.0   6.0  6.0  16.0  ...   \n",
       "3          8.0   9.0  54.0  13.0    1.0  10.0   14.0   7.0  2.0   8.0  ...   \n",
       "4          7.0   7.0  13.0  24.0    2.0   6.0   12.0   8.0  2.0   4.0  ...   \n",
       "5         80.0   5.0   1.0   2.0  175.0  42.0  102.0  23.0  4.0  35.0  ...   \n",
       "...        ...   ...   ...   ...    ...   ...    ...   ...  ...   ...  ...   \n",
       "939       15.0  11.0   2.0   1.0    7.0  14.0   16.0   4.0  1.0   6.0  ...   \n",
       "940       52.0  17.0  15.0  10.0   28.0  54.0   68.0  18.0  6.0  51.0  ...   \n",
       "941       10.0   7.0   4.0   4.0    6.0  11.0    7.0   7.0  3.0   6.0  ...   \n",
       "942       27.0  12.0   9.0   8.0   17.0  40.0   46.0  11.0  4.0  24.0  ...   \n",
       "943       83.0   9.0   2.0   4.0   59.0  50.0  108.0  26.0  4.0  34.0  ...   \n",
       "\n",
       "user_id   934   935   936   937   938   939    940   941   942    943  \n",
       "user_id                                                                \n",
       "1        77.0  15.0  48.0  19.0  36.0  15.0   52.0  10.0  27.0   83.0  \n",
       "2        15.0  14.0  33.0  20.0  24.0  11.0   17.0   7.0  12.0    9.0  \n",
       "3         3.0   2.0  16.0   6.0  10.0   2.0   15.0   4.0   9.0    2.0  \n",
       "4         3.0   1.0   8.0   6.0   7.0   1.0   10.0   4.0   8.0    4.0  \n",
       "5        58.0   6.0  15.0   5.0  21.0   7.0   28.0   6.0  17.0   59.0  \n",
       "...       ...   ...   ...   ...   ...   ...    ...   ...   ...    ...  \n",
       "939       7.0  18.0  23.0  10.0  29.0  49.0    5.0   6.0   3.0   12.0  \n",
       "940      45.0   7.0  26.0  13.0  18.0   5.0  107.0   7.0  23.0   28.0  \n",
       "941       3.0   6.0  16.0   7.0  14.0   6.0    7.0  22.0   4.0    5.0  \n",
       "942      27.0   4.0  12.0   6.0  10.0   3.0   23.0   4.0  79.0   19.0  \n",
       "943      45.0  16.0  22.0   6.0  27.0  12.0   28.0   5.0  19.0  168.0  \n",
       "\n",
       "[943 rows x 943 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_binary = np.array((rating_matrix > 0).astype(float))\n",
    "counts = np.dot(rating_binary, rating_binary.T)\n",
    "counts = pd.DataFrame(counts, index=rating_matrix.index, columns=rating_matrix.index).fillna(0)\n",
    "# 공통으로 평가한 영화의 수 \n",
    "counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이웃을 전체 사용자로 설정\n",
    "def CF_knn_bias_sig(user_id:str, movie_id:str, simil: str, neighbor_size: int) -> float:\n",
    "  \"\"\"\n",
    "  주어진 영화에 대해서 평가한 사용자에 대해서, 평점을 기반으로 유사도를 계산하고, \n",
    "  유사도와 평점을 가중평균해 예측치를 구함.\\n\n",
    "  유사도 기준 상위 neighbor_size(=k)만큼을 이웃으로 정의. 이웃에 대해서만 가중평균을 진행.\\n\n",
    "  사용자의 평가경향을 고려 \\n\n",
    "  신뢰도(공통으로 평가한 아이템의 개수)가 특정값이상(전역변수로 정의)인 유저만 이웃으로 사용. \\n\n",
    "  \n",
    "  Args:\n",
    "      user_id (str): 사용자 id \\n\n",
    "      movie_id (str): 영화 id \\n\n",
    "      simil (str): similarity계산 방식 ( cosine or corr ) \\n\n",
    "      neighbor_size (int): 이웃의 수 \\n\n",
    "  Returns:\n",
    "      float: user id와 movie id를 평가한 사용자에 대한, 유사도로 평점을 가중평균한 예측치\n",
    "  \"\"\"\n",
    "  \n",
    "  # 구할 수 없는 경우에는 평균평점으로 대체한다.\n",
    "  default_rating = rating_mean[user_id]\n",
    "  \n",
    "  # 유사도 기준 설정. \n",
    "  if simil == 'cosine':\n",
    "    similarity = user_similarity\n",
    "  else:\n",
    "    similarity = user_corr\n",
    "  \n",
    "  # 해당 movie id에 대해서 평가한 값이 있는지 확인 ( train set에 movie id가 있는지 확인 )\n",
    "  if movie_id in rating_matrix.columns:\n",
    "    movie_ratings = rating_bias[movie_id].copy() #  rating_bias를 이용해 평가경향 제거해줌.\n",
    "    \n",
    "    common_counts = counts[user_id] # 공통으로 평가한 영화의 수\n",
    "    low_significance = common_counts < SIG_LEVEL # 공통으로 평가한 영화의 수 < SIG_LVEL\n",
    "    no_rating = movie_ratings.isnull() # movie_id에 대해서 평가하지 않은 user \n",
    "    none_rating_idx = movie_ratings[no_rating | low_significance].index # 평가한 영화가 없거나, 신뢰도가 낮은 user id.\n",
    "    movie_ratings = movie_ratings.dropna()\n",
    "    \n",
    "    sim_scores = similarity[user_id].copy()\n",
    "    sim_scores = sim_scores.dropna()\n",
    "    # 평가하지 않은 유저 + 신뢰도가 SIG_LEVEL보다 작은 유저 뺴주기\n",
    "    sim_scores = sim_scores.drop(none_rating_idx, axis=0)\n",
    "    \n",
    "    # 유사도 개수가 MIN_RATINGS보다 작으면 평균값으로 예측\n",
    "    if len(sim_scores) < MIN_RATINGS:\n",
    "      return default_rating\n",
    "    \n",
    "    # 주어진 영화에 대해서 평가한 각 사용자에 대해서 평점을 유사도로 가중평균한 예측치를 구함\n",
    "    # k가 0인경우 ( 안주어진 경우 )\n",
    "    if neighbor_size == 0:\n",
    "      mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "    # K가 주어진 경우\n",
    "    else:\n",
    "      sim_scores = sim_scores.sort_values(ascending=False)\n",
    " \n",
    "      neighbor_size = min(neighbor_size, len(sim_scores))\n",
    "      \n",
    "      sim_scores = sim_scores[:neighbor_size]      \n",
    "      movie_ratings = movie_ratings[sim_scores.index][:neighbor_size]\n",
    "      \n",
    "      # 사용자의 평가경향 더 해줌\n",
    "      mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum() + default_rating\n",
    "  # 없으면 3.0으로 예측\n",
    "  else:\n",
    "    mean_rating = default_rating\n",
    "    \n",
    "  return mean_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: basic model / rmse: 1.0142086411731543\n",
      "model: bias reducing model / rmse: 0.9441684573734636\n",
      "model: bias reducing + sig model / rmse: 0.9433936802841534\n"
     ]
    }
   ],
   "source": [
    "# train set에 대해서 측정\n",
    "# CF_knn 보완해야되는 부분. 따로 user_similarity, user_corr 할당해주고 써야되는 문제.\n",
    "X = ratings.copy();y = ratings['user_id']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=25)\n",
    "rating_matrix = X_train.pivot(index=\"user_id\", columns='movie_id', values='rating')\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "user_corr = matrix_dummy.T.corr()\n",
    "user_corr = pd.DataFrame(user_corr, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "rating_mean = rating_matrix.mean(axis=1)\n",
    "rating_bias = (rating_matrix.T - rating_mean).T # 평가경향 제거\n",
    "\n",
    "rating_binary = np.array((rating_matrix > 0).astype(float))\n",
    "counts = np.dot(rating_binary, rating_binary.T)\n",
    "counts = pd.DataFrame(counts, index=rating_matrix.index, columns=rating_matrix.index).fillna(0)\n",
    "counts # 공통으로 평가한 영화의 수 \n",
    "\n",
    "SIG_LEVEL = 3 # 최소 신뢰도\n",
    "MIN_RATINGS = 2 # 최소 유사도 개수\n",
    "\n",
    "print(f\"model: basic model / rmse: {score_CF(CF_knn, simil='cosine', neighbor_size=30)}\")\n",
    "print(f\"model: bias reducing model / rmse: {score_CF(CF_knn_bias, simil='cosine', neighbor_size=30)}\")\n",
    "print(f\"model: bias reducing + sig model / rmse: {score_CF(CF_knn_bias_sig, simil='cosine', neighbor_size=30)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연습문제   \n",
    "결과 수정해주기 (1보다 작은건 1로, 5보다 큰 건 5로 예측하기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_result(result:float) -> float:\n",
    "  \"\"\"rating의 값은 1~5사이의 값을 가지므로, 1이하면 1로, 5이상이면 5로 값을 바꿔주기\n",
    "\n",
    "  Args:\n",
    "      result (float): 모델의 결과값. 가중평균. 예측치.\n",
    "\n",
    "  Returns:\n",
    "      float: 수정된 결과값.\n",
    "  \"\"\"\n",
    "  if (result < 1): return 1\n",
    "  if (result > 5): return 5\n",
    "  return result\n",
    "\n",
    "\n",
    "# 이웃을 전체 사용자로 설정\n",
    "def CF_knn_bias_sig_check(user_id:str, movie_id:str, simil: str, neighbor_size: int) -> float:\n",
    "  \"\"\"\n",
    "  주어진 영화에 대해서 평가한 사용자에 대해서, 평점을 기반으로 유사도를 계산하고, \n",
    "  유사도와 평점을 가중평균해 예측치를 구함.\\n\n",
    "  유사도 기준 상위 neighbor_size(=k)만큼을 이웃으로 정의. 이웃에 대해서만 가중평균을 진행.\\n\n",
    "  사용자의 평가경향을 고려 \\n\n",
    "  신뢰도(공통으로 평가한 아이템의 개수)가 특정값이상(전역변수로 정의)인 유저만 이웃으로 사용. \\n\n",
    "  조건을 거쳐 나온 유사도의 개수가 특정값(전역변수로 정의)이하면 평균값으로 예측 \\n\n",
    "  결과값이 1이하면 1, 5이상이면 5로 바꿔줌 \\n\n",
    "  \n",
    "  Args:\n",
    "      user_id (str): 사용자 id \\n\n",
    "      movie_id (str): 영화 id \\n\n",
    "      simil (str): similarity계산 방식 ( cosine or corr ) \\n\n",
    "      neighbor_size (int): 이웃의 수 \\n\n",
    "  Returns:\n",
    "      float: user id와 movie id를 평가한 사용자에 대한, 유사도로 평점을 가중평균한 예측치\n",
    "  \"\"\"\n",
    "  \n",
    "  # 구할 수 없는 경우에는 평균평점으로 대체한다.\n",
    "  default_rating = rating_mean[user_id]\n",
    "  \n",
    "  # 유사도 기준 설정. \n",
    "  if simil == 'cosine':\n",
    "    similarity = user_similarity\n",
    "  else:\n",
    "    similarity = user_corr\n",
    "  \n",
    "  # 해당 movie id에 대해서 평가한 값이 있는지 확인 ( train set에 movie id가 있는지 확인 )\n",
    "  if movie_id in rating_matrix.columns:\n",
    "    movie_ratings = rating_bias[movie_id].copy() #  rating_bias를 이용해 평가경향 제거해줌.\n",
    "    \n",
    "    common_counts = counts[user_id] # 공통으로 평가한 영화의 수\n",
    "    low_significance = common_counts < SIG_LEVEL # 공통으로 평가한 영화의 수 < SIG_LVEL\n",
    "    no_rating = movie_ratings.isnull() # movie_id에 대해서 평가하지 않은 user \n",
    "    none_rating_idx = movie_ratings[no_rating | low_significance].index # 평가한 영화가 없거나, 신뢰도가 낮은 user id.\n",
    "    movie_ratings = movie_ratings.dropna()\n",
    "    \n",
    "    sim_scores = similarity[user_id].copy()\n",
    "    sim_scores = sim_scores.dropna()\n",
    "    # 평가하지 않은 유저 + 신뢰도가 SIG_LEVEL보다 작은 유저 뺴주기\n",
    "    sim_scores = sim_scores.drop(none_rating_idx, axis=0)\n",
    "    \n",
    "    # 유사도 개수가 MIN_RATINGS보다 작으면 평균값으로 예측\n",
    "    if len(sim_scores) < MIN_RATINGS:\n",
    "      return default_rating\n",
    "    \n",
    "    # 주어진 영화에 대해서 평가한 각 사용자에 대해서 평점을 유사도로 가중평균한 예측치를 구함\n",
    "    # k가 0인경우 ( 안주어진 경우 )\n",
    "    if neighbor_size == 0:\n",
    "      mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "    # K가 주어진 경우\n",
    "    else:\n",
    "      sim_scores = sim_scores.sort_values(ascending=False)\n",
    " \n",
    "      neighbor_size = min(neighbor_size, len(sim_scores))\n",
    "      \n",
    "      sim_scores = sim_scores[:neighbor_size]      \n",
    "      movie_ratings = movie_ratings[sim_scores.index][:neighbor_size]\n",
    "      \n",
    "      # 사용자의 평가경향 더 해줌\n",
    "      mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum() + default_rating\n",
    "  # 없으면 3.0으로 예측\n",
    "  else:\n",
    "    mean_rating = default_rating\n",
    "    \n",
    "  return check_result(mean_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: basic model / rmse: 1.0142086411731543\n",
      "model: bias reducing model / rmse: 0.9441684573734636\n",
      "model: bias reducing + sig + min_rating model / rmse: 0.9433936802841534\n",
      "model: bias reducing + sig + min_rating + check model / rmse: 0.9419892244765159\n"
     ]
    }
   ],
   "source": [
    "# train set에 대해서 측정\n",
    "# CF_knn 보완해야되는 부분. 따로 user_similarity, user_corr 할당해주고 써야되는 문제.\n",
    "X = ratings.copy();y = ratings['user_id']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=25)\n",
    "rating_matrix = X_train.pivot(index=\"user_id\", columns='movie_id', values='rating')\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "user_corr = matrix_dummy.T.corr()\n",
    "user_corr = pd.DataFrame(user_corr, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "rating_mean = rating_matrix.mean(axis=1)\n",
    "rating_bias = (rating_matrix.T - rating_mean).T # 평가경향 제거\n",
    "\n",
    "rating_binary = np.array((rating_matrix > 0).astype(float))\n",
    "counts = np.dot(rating_binary, rating_binary.T)\n",
    "counts = pd.DataFrame(counts, index=rating_matrix.index, columns=rating_matrix.index).fillna(0)\n",
    "counts # 공통으로 평가한 영화의 수 \n",
    "\n",
    "SIG_LEVEL = 3 # 최소 신뢰도\n",
    "MIN_RATINGS = 2 # 최소 유사도 개수\n",
    "\n",
    "print(f\"model: basic model / rmse: {score_CF(CF_knn, simil='cosine', neighbor_size=30)}\")\n",
    "print(f\"model: bias reducing model / rmse: {score_CF(CF_knn_bias, simil='cosine', neighbor_size=30)}\")\n",
    "print(f\"model: bias reducing + sig + min_rating model / rmse: {score_CF(CF_knn_bias_sig, simil='cosine', neighbor_size=30)}\")\n",
    "print(f\"model: bias reducing + sig + min_rating + check model / rmse: {score_CF(CF_knn_bias_sig_check, simil='cosine', neighbor_size=30)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UBCF vs IBCF  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "X = ratings.copy();y = ratings['user_id']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=25)\n",
    "rating_matrix = X_train.pivot(index=\"user_id\", columns='movie_id', values='rating')\n",
    "\n",
    "rating_matrix_t = np.transpose(rating_matrix)\n",
    "matrix_dummy = rating_matrix_t.copy().fillna(0)\n",
    "\n",
    "item_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "item_similarity = pd.DataFrame(item_similarity, index=rating_matrix_t.index, columns=rating_matrix_t.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CF_IBCF(user_id:str, movie_id:str):\n",
    "  if movie_id in item_similarity.index:\n",
    "    user_rating = rating_matrix_t[user_id]\n",
    "    none_rating_idx = user_rating[user_rating.isnull()].index # 유저가 평가하지 않은 영화 \n",
    "    user_rating = user_rating.dropna()\n",
    "    \n",
    "    sim_scores = item_similarity[movie_id]\n",
    "    sim_scores = sim_scores.drop(none_rating_idx, axis=0)\n",
    "    mean_rating = np.dot(sim_scores, user_rating) / sim_scores.sum()\n",
    "  else:\n",
    "    mean_rating = 3.0\n",
    "  \n",
    "  return mean_rating\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 in item_similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant_39",
   "language": "python",
   "name": "quant_39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
